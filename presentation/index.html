<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Reveal.js Presentation with Markdown and Step-by-Step Code Highlights</title>

    <!-- Core Reveal.js styles -->
    <link rel="stylesheet" href="node_modules/reveal.js/dist/reveal.css">
    <link rel="stylesheet" href="node_modules/reveal.js/dist/theme/white.css">

    <!-- Highlight.js styles for syntax highlighting -->
    <link rel="stylesheet" href="node_modules/highlight.js/styles/default.css">
</head>
<body>
<div class="reveal">
    <div class="slides">
        <section data-markdown>
        <textarea data-template>
          # Building AI Agents with Go
          ## A Practical Guide
          <img src="https://golang.org/doc/gopher/frontpage.png" alt="Gopher" width="100">
          <footer>by Yoni Davidson</footer>
        </textarea>
        </section>
        <section data-markdown>
        <textarea data-template>
          ## About me!
          - Married + 1 Daughter and 4 dogs
          <hr/>
          - **Squad Manager @Tabnine** (Current)
          - Founding Engineer At Ariga
          - Data Architect / Tech lead at Bond
          - SW Engineer at Sears Israel
          - SW Engineer at Eyesgiht mobile
          - SW Engineer at Alvarion
          
          Note:
          * I have large experience in dev tools, AI applications and data engineering.
          * Living in Pardes Chana like many known gophers such as Miki (not far from me).    
          * I manage the remote squad at Tabnine - which is a cool twist for working hybried 
          * At Tabnine we build AI applications for example
            Chat, Agents, RAG (client and server)
          * Our main languages are typescript , Python and Rust - but I dream at Go at night (and sometimes during the day)
          * This talk is about building AI agents with Go, which notes for building AI applications if we were gophers.
        </textarea>
        </section>
        <section data-markdown>
        <textarea data-template>
          ## Agenda
          - State of AI (why wasn’t this talk done last year?)
          - How do we 'talk' with LLMs
          - Prompt engineering
          - RAG
          - One shot agents
          - Workflow agents
        </textarea>
        </section>
        <section data-markdown>
        <textarea data-template>
          ## State of AI
          - Pricing
          - Availability
          - Privacy      
        </textarea>
        </section>
        <section data-markdown>
          <textarea data-template>
            ## State of AI - Pricing 
            ######  <div style="text-align: left;"> 1M Tokens roughly the equivalent of 2500 pages in a standard book</div>
            | Model            | Price per 1M input tokens | Price per 1M output tokens |
            |------------------|---------------------------|----------------------------|            
            | GPT-4o mini      | $0.15                     | $0.6                       |
            | Gemini 1.5 Flash | $0.075                    | $0.30                      |            
          </textarea>
        </section>
        <section data-markdown>
          <textarea data-template>
            ## State of AI - Availability
            | Cloud Provider | Claude 3.5 | GPT-4o-mini | LLaMA 3.1 | Gemini 1.5 Flash  | Mistral  |
            |----------------|------------|-------------|-----------|-------------------|----------|
            | Azure          |            |   ✓         |     ✓     |                   |    ✓     |
            | AWS            |     ✓      |             |     ✓     |                   |    ✓     |
            | Google Cloud   |    ✓       |             |     ✓     |  ✓                |    ✓     |
          </textarea>
        </section>
        <section data-markdown>
          <textarea data-template>
            ## State of AI - Privacy
            
            * Cloud providers provide both SDK based protection accessing your LLM but also ensure that they don't store or train on your data.
            * Most AI providers today have "Enterprise" tiers that ensure data protection.
          </textarea>
        </section>
        <section data-markdown>
          <textarea data-template>
            ## How do we 'talk' with LLMs
            
            * The world is split into Providers and AI Models
            
            * For example - Azure and OpenAI are providers for the GPT-4o-mini model
          </textarea>
        </section>
        <section data-markdown>
          <textarea data-template>
            ## How do we 'talk' with LLMs
            
            * OpenAI client - Demo
            ```shell
            go run ./cmd/talk
            ```
            
          </textarea>
        </section>    
        <section data-markdown>
        <textarea data-template>
          ## How do we 'talk' with LLMs - OpenAI Provider                  
          ```go [1-8|9-22|23-67|]
          // ChatCompletion sends a request to the OpenAI API and returns the response as a byte slice.
func (p OpenAIProvider) ChatCompletion(m []prompt.Message) ([]byte, error) {
	// convert from []prompt.Message to []message
	messages := make([]message, len(m))
	for i, m := range m {
		messages[i] = message{
			Role:    string(m.Role),
			Content: m.Content,
		}
	}
	// Define the payload with a system talk
	payload := requestPayload{
		Model:       "gpt-4o-mini-2024-07-18",
		Messages:    messages,
		MaxTokens:   1000,
		Temperature: 0.5,
		TopP:        1.0,
		N:           1,
		Stop:        nil,
	}

	// Marshal the payload into JSON
	payloadBytes, err := json.Marshal(payload)
	if err != nil {
		return nil, err
	}

	// Create the HTTP request
	req, err := http.NewRequest("POST", endpoint, bytes.NewBuffer(payloadBytes))
	if err != nil {
		return nil, err
	}

	// Set the necessary headers
	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("Authorization", "Bearer "+p.APIKey)

	// Execute the request
	client := &http.Client{}
	resp, err := client.Do(req)
	if err != nil {
		return nil, err
	}
	defer func(Body io.ReadCloser) {
		err := Body.Close()
		if err != nil {
			fmt.Println(err)
		}
	}(resp.Body)
	// Read the response body
	body, err := io.ReadAll(resp.Body)
	if err != nil {
		return nil, err
	}

	// Check if the request was successful
	if resp.StatusCode != http.StatusOK {
		return nil, fmt.Errorf("unexpected status code: %d, body: %s", resp.StatusCode, string(body))
	}
	var responsePayload responsePayload
	if err := json.Unmarshal(body, &responsePayload); err != nil {
		return nil, err
	}

	return []byte(responsePayload.Choices[0].Message.Content), nil
}
          ```
        </textarea>
        </section>
         <!--<section>
          <textarea data-markdown=>
            ### Ollama
          </textarea>
        </section> -->
    </div>
</div>

<!-- Include Reveal.js core library -->
<script src="node_modules/reveal.js/dist/reveal.js"></script>

<!-- Include Highlight.js library -->
<script src="node_modules/highlight.js/lib/index.js"></script>

<!-- Include the Highlight.js plugin for Reveal.js -->
<script src="node_modules/reveal.js/plugin/highlight/highlight.js"></script>

<!-- Include the Markdown plugin for Reveal.js -->
<script src="node_modules/reveal.js/plugin/markdown/markdown.js"></script>

<script src="node_modules/reveal.js/plugin/notes/notes.js"></script>
<script src="socket.io/socket.io.js"></script>
<script src="node_modules/reveal-notes-server/client.js"></script>

<!-- Initialize Reveal.js and Highlight.js -->
<script>
    // Initialize Reveal.js
    Reveal.initialize({
        plugins: [RevealMarkdown, RevealHighlight, RevealNotes],
    });

    // Initialize syntax highlighting
    hljs.highlightAll();
</script>
</body>
</html>
